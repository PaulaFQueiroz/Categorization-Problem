covid=read.csv("C:/Users/pauli/OneDrive/Documentos/Classes 2022/Indp_Study/data/COVID_TCR.csv",header=T,na.strings = "?")
healthyD=read.csv("C:/Users/pauli/OneDrive/Documentos/Classes 2022/Indp_Study/data/HD_TCR.csv",header=T,na.strings = "?")
#Merge of two datasets
covid_healthy <-  merge( covid, healthyD, by = "vjGene",all=T )
#assigning first column as row name so we can transpose
row.names(covid_healthy) <- covid_healthy$vjGene
covid_healthy$vjGene <- NULL
#transpose covid_healthy since we are interested in gene(at columns)
dt <- t(covid_healthy)
#make dt numeric to deal with Nas (Nas are introduced)
class(dt) <- "numeric"
#set Nas to zero
dt[is.na(dt)] = 10^(-7)
# apply log transformatin
logdt <- log(dt)
#normalize each column
normDt <- scale(logdt)
###########################################################
#create a vector to count number of columns with unique values less than or equal to 3
list = apply(normDt, 2, function(x) length(unique(x))) <= 3
#count of <=3 unique values : 27
#length(list[list== TRUE])
#name of columns wurh less then or equal to 3 unique values
#print(list[list== TRUE])
###################################################################
#create new data normDtnew selecting only columns that have more than 3 unique values
normDtnew = as.data.frame(normDt)
library(dplyr)
normDtnew = normDtnew %>% select(where(~ n_distinct(.) > 3))
dim(normDtnew)
#check if there is columns with unique values less than or equal to 3
#list2 = apply(normDtnew, 2, function(x) length(unique(x))) <= 3
#length(list2[list2== TRUE])
#print(list2[list2== TRUE])
################################### PCA geneUsage
#run pca
library(ggfortify)
pca_usage <- prcomp(normDtnew, scale. = TRUE)
#plot pca
#autoplot(pca_res)
#summary of pca eigenvalues and how much data is explained in each
summary(pca_usage)
#percentage of expained variances by dimentions
library(factoextra)
fviz_screeplot(pca_usage)
#name column to apply color on plots
library("dplyr")
data <- normDtnew        # Duplicate data
data <- tibble::rownames_to_column(data, "vjGene") # Apply rownames to column
#plot
autoplot(pca_usage, data = data, colour = 'vjGene', legendLabs=NULL)
autoplot(pca_usage, data = data, colour = 'vjGene', shape = FALSE, label.size = 3)
View(normDtnew)
#################################################
###########   PCA Abundance   ###################
#################################################
covidvjg=read.csv("C:/Users/pauli/OneDrive/Documentos/Classes 2022/Indp_Study/data/COVID_TCR_vjG.csv",header=T,na.strings = "?")
healthyDvjg=read.csv("C:/Users/pauli/OneDrive/Documentos/Classes 2022/Indp_Study/data/HD_TCR_vjG.csv",header=T,na.strings = "?")
covid_healthy_vjg <-  merge(covidvjg, healthyDvjg, by = "vjGene",all=T )
#convert "NA" to 0
covid_healthy_vjg[covid_healthy_vjg=="NA"] <- 0
#convert characters to numeric in all except 1st column
covid_healthy_vjg[,-1] <- as.data.frame(apply(covid_healthy_vjg[,-1], 2, as.numeric))
#sapply(covid_healthy_vjg, class)
#assigning first column as row name
row.names(covid_healthy_vjg) <- covid_healthy_vjg$vjGene
covid_healthy_vjg$vjGene <- NULL
#View(covid_healthy_vjg)
#divide each number by sum of times the gene appears (row sum)
covid_healthy_vjg <- t(apply(covid_healthy_vjg, 1, function(x) x/sum(x)))
#set 0 to 10^-7
covid_healthy_vjg[covid_healthy_vjg==0] <- 10^-7
#transpose covid_healthy
dtvjg <- t(covid_healthy_vjg)
#Take log of all non-zero values
df_dtvjg <- data.frame(dtvjg)
library(plyr)
f <- numcolwise(log)
logdtvjg <- f(df_dtvjg)
rownames(logdtvjg) <- rownames(df_dtvjg)
#View(logdtvjg)
#normalize it
normDtvjg <- scale(logdtvjg)
#create a vector to count number of columns with unique values less than or equal to 3
list2 = apply(normDtvjg, 2, function(x) length(unique(x))) <= 3
#Get # of unique values in each column and sort
list2len = apply(normDtvjg, 2, function(x) length(unique(x)))
list2len[order(unlist(list2len), decreasing=TRUE)]
#count: getting 83 now, but not sure why it's different than 27
#length(list2[list2== TRUE])
#print(list2[list2== TRUE])
#make normdt data frame to avoid error
#create new normDtnew selecting only columns that have more tham 3 unique values
library(dplyr)
normDtnewvjg = as.data.frame(normDtvjg)
normDtnewvjg = normDtnewvjg %>% select(where(~ n_distinct(.) > 3))
list3 = apply(normDtnewvjg, 2, function(x) length(unique(x))) <= 3
#double check count of unique
#length(list3[list3== TRUE])
#print(list3[list3== TRUE])
############################################## pca
library(ggfortify)
pca_abundance <- prcomp(normDtnewvjg, scale. = TRUE)
#autoplot(pca_abundance)
summary(pca_abundance)
#percentage of expained variances by dimentions
library(factoextra)
fviz_screeplot(pca_abundance)
# Install & load dplyr
library("dplyr")
#Now, we can use the rownames_to_column function to add the row names of our data as variable:
dataVjGene <- normDtnewvjg  # Duplicate example data
dataVjGene <- tibble::rownames_to_column(dataVjGene, "vjGene") # Apply rownames_to_column
#plot
autoplot(pca_abundance, data = dataVjGene, colour = 'vjGene')
#plot label
autoplot(pca_abundance, data = dataVjGene, colour = 'vjGene', shape = FALSE, label.size = 3)
# Load the datasets
covidvjg=read.csv("C:/Users/pauli/OneDrive/Documentos/Classes 2022/Indp_Study/data/COVID_TCR_vjG.csv",header=T,na.strings = "?")
healthyDvjg=read.csv("C:/Users/pauli/OneDrive/Documentos/Classes 2022/Indp_Study/data/HD_TCR_vjG.csv",header=T,na.strings = "?")
covid_healthy_vjg <-  merge(covidvjg, healthyDvjg, by = "vjGene",all=T )
# Set row names and remove 'vjGene' column
row.names(covid_healthy_vjg) <- covid_healthy_vjg$vjGene
covid_healthy_vjg$vjGene <- NULL
# Convert "NA" to 0
covid_healthy_vjg[covid_healthy_vjg == "NA"] <- 0
# Convert characters to numeric in all except the 1st column
covid_healthy_vjg[, -1] <- as.data.frame(apply(covid_healthy_vjg[, -1], 2, as.numeric))
# Assign the first column as row names and remove 'vjGene' column
row.names(covid_healthy_vjg) <- covid_healthy_vjg$vjGene
covid_healthy_vjg$vjGene <- NULL
# Divide each number by the sum of times the gene appears (row sum)
covid_healthy_vjg <- t(apply(covid_healthy_vjg, 1, function(x) x / sum(x)))
# Convert the entire matrix to numeric
covid_healthy_vjg <- apply(covid_healthy_vjg, 2, as.numeric)
# Now, divide each number by the sum of times the gene appears (row sum)
covid_healthy_vjg <- t(apply(covid_healthy_vjg, 1, function(x) x / sum(x, na.rm = TRUE)))
# Set 0 values to 10^-7
covid_healthy_vjg[covid_healthy_vjg == 0] <- 10^-7
# Transpose covid_healthy_vjg
dtvjg <- t(covid_healthy_vjg)
# Take the log of all non-zero values
library(plyr)
logdtvjg <- numcolwise(log)(as.data.frame(dtvjg))
rownames(logdtvjg) <- rownames(dtvjg)
# Normalize it
normDtvjg <- scale(logdtvjg)
#make dt numeric (Nas are introduced)
class(dt) <- "numeric"
# Replace NAs with 10^(-7)
dt[is.na(dt)] <- 10^(-7)
# Apply log transformation
logdt <- log(dt)
# Normalize each column
normDt <- scale(logdt)
# Calculate the number of unique values for each column
# This line computes the number of unique values in each column of the 'normDt' data frame.
unique_counts <- apply(normDtvjg, 2, function(x) length(unique(x)))
## Here, we filter the columns in 'normDt' to keep only those with more than 3 unique values.
normDtvjg_filtered <- normDtvjg[, unique_counts > 3]
normDt_filtered
dim(normDt_filtered)
dim(normDtvjg_filtered)
# Check the number of columns in the original and filtered data frames
num_original_columns <- ncol(normDtvjg)
num_filtered_columns <- ncol(normDtvjg_filtered)
# Print the results
cat("Original number of columns:", num_original_columns, "\n")
cat("Number of columns after filtering:", num_filtered_columns, "\n")
# Calculate the number of columns deleted
num_columns_deleted <- num_original_columns - num_filtered_columns
cat("Number of columns deleted:", num_columns_deleted, "\n")
# Run PCA on the normDt_filtered dataset
pca_abundance <- prcomp(normDtvjg_filtered, scale. = TRUE)
library(ggfortify)
pca_abundance <- prcomp(normDtvjg_filtered, scale. = TRUE)
normDtnewvjg = as.data.frame(normDtvjg_filtered)
pca_abundance <- prcomp(normDtvjg_filtered, scale. = TRUE)
covidvjg=read.csv("C:/Users/pauli/OneDrive/Documentos/Classes 2022/Indp_Study/data/COVID_TCR_vjG.csv",header=T,na.strings = "?")
healthyDvjg=read.csv("C:/Users/pauli/OneDrive/Documentos/Classes 2022/Indp_Study/data/HD_TCR_vjG.csv",header=T,na.strings = "?")
covid_healthy_vjg <-  merge(covidvjg, healthyDvjg, by = "vjGene",all=T )
#convert "NA" to 0
covid_healthy_vjg[covid_healthy_vjg=="NA"] <- 0
#convert characters to numeric in all except 1st column
covid_healthy_vjg[,-1] <- as.data.frame(apply(covid_healthy_vjg[,-1], 2, as.numeric))
#assigning first column as row name
row.names(covid_healthy_vjg) <- covid_healthy_vjg$vjGene
covid_healthy_vjg$vjGene <- NULL
#View(covid_healthy_vjg)
#divide each number by sum of times the gene appears (row sum)
covid_healthy_vjg <- t(apply(covid_healthy_vjg, 1, function(x) x/sum(x)))
#set 0 to 10^-7
covid_healthy_vjg[covid_healthy_vjg==0] <- 10^-7
#transpose covid_healthy
dtvjg <- t(covid_healthy_vjg)
#Take log of all non-zero values
df_dtvjg <- data.frame(dtvjg)
library(plyr)
f <- numcolwise(log)
logdtvjg <- f(df_dtvjg)
rownames(logdtvjg) <- rownames(df_dtvjg)
#normalize it
normDtvjg <- scale(logdtvjg)
#create a vector to count number of columns with unique values less than or equal to 3
list2 = apply(normDtvjg, 2, function(x) length(unique(x))) <= 3
#Get # of unique values in each column and sort
list2len = apply(normDtvjg, 2, function(x) length(unique(x)))
list2len[order(unlist(list2len), decreasing=TRUE)]
library(dplyr)
normDtnewvjg = as.data.frame(normDtvjg)
normDtnewvjg = normDtnewvjg %>% select(where(~ n_distinct(.) > 3))
list3 = apply(normDtnewvjg, 2, function(x) length(unique(x))) <= 3
library(ggfortify)
pca_abundance <- prcomp(normDtnewvjg, scale. = TRUE)
##############################  Principal Component Analysis ##################
library(dplyr)
library(plyr)
library(ggfortify)
# Read CSV files and handle NAs during import
covidvjg <- read.csv("C:/Users/pauli/OneDrive/Documentos/Classes 2022/Indp_Study/data/COVID_TCR_vjG.csv", header = TRUE, na.strings = "?")
healthyDvjg <- read.csv("C:/Users/pauli/OneDrive/Documentos/Classes 2022/Indp_Study/data/HD_TCR_vjG.csv", header = TRUE, na.strings = "?")
# Merge datasets
covid_healthy_vjg <- merge(covidvjg, healthyDvjg, by = "vjGene", all = TRUE)
# Replace "NA" with 0
covid_healthy_vjg[covid_healthy_vjg == "NA"] <- 0
# Convert columns (except the first one) to numeric
covid_healthy_vjg[-1] <- sapply(covid_healthy_vjg[-1], as.numeric)
# Set row names and remove vjGene column
covid_healthy_vjg <- covid_healthy_vjg %>%
column_to_rownames(var = "vjGene") %>%
select(-vjGene)
# Set row names and remove vjGene column
rownames(covid_healthy_vjg) <- covid_healthy_vjg$vjGene
covid_healthy_vjg$vjGene <- NULL
# Divide each number by the sum of times the gene appears (row sum)
covid_healthy_vjg <- t(apply(covid_healthy_vjg, 1, function(x) x / sum(x)))
# Set 0 to 10^-7
covid_healthy_vjg[covid_healthy_vjg == 0] <- 1e-7
# Take the log of all non-zero values
logdtvjg <- covid_healthy_vjg %>%
as.data.frame() %>%
numcolwise(log) %>%
column_to_rownames(var = "Row.names")
# Take the logarithm of the values
logdtvjg[, -1] <- log(logdtvjg[, -1])
#transpose covid_healthy
dtvjg <- t(covid_healthy_vjg)
#Take log of all non-zero values
df_dtvjg <- data.frame(dtvjg)
library(plyr)
f <- numcolwise(log)
logdtvjg <- f(df_dtvjg)
rownames(logdtvjg) <- rownames(df_dtvjg)
View(logdtvjg)
# Normalize the data
normDtvjg <- scale(logdtvjg)
# Calculate the number of unique values for each column
# This line computes the number of unique values in each column of the 'normDt' data frame.
unique_counts <- apply(normDtvjg, 2, function(x) length(unique(x)))
## Here, we filter the columns in 'normDt' to keep only those with more than 3 unique values.
normDtvjg_filtered <- normDtvjg[, unique_counts > 3]
dim(normDtvjg_filtered)
# Check the number of columns in the original and filtered data frames
num_original_columns <- ncol(normDtvjg)
num_filtered_columns <- ncol(normDtvjg_filtered)
# Print the results
cat("Original number of columns:", num_original_columns, "\n")
cat("Number of columns after filtering:", num_filtered_columns, "\n")
# Calculate the number of columns deleted
num_columns_deleted <- num_original_columns - num_filtered_columns
cat("Number of columns deleted:", num_columns_deleted, "\n")
# Perform PCA
pca_abundance <- prcomp(normDtvjg_filtered, scale. = TRUE)
# Summary of PCA eigenvalues and explained variances
summary(pca_abundance)
library(factoextra)
fviz_screeplot(pca_abundance)
#Now, we can use the rownames_to_column function to add the row names of our data as variable:
dataVjGene <- normDtvjg_filtered  # Duplicate example data
dataVjGene <- tibble::rownames_to_column(dataVjGene, "vjGene") # Apply rownames_to_column
#plot
autoplot(pca_abundance, data = dataVjGene, colour = 'vjGene')
#plot label
autoplot(pca_abundance, data = dataVjGene, colour = 'vjGene', shape = FALSE, label.size = 3)
library(ggfortify)
# Check the number of columns in the original and filtered data frames
num_original_columns <- ncol(normDtvjg)
num_filtered_columns <- ncol(normDtvjg_filtered)
# Print the results
cat("Original number of columns:", num_original_columns, "\n")
cat("Number of columns after filtering:", num_filtered_columns, "\n")
# Calculate the number of columns deleted
num_columns_deleted <- num_original_columns - num_filtered_columns
cat("Number of columns deleted:", num_columns_deleted, "\n")
# Perform PCA
pca_abundance <- prcomp(normDtvjg_filtered, scale. = TRUE)
# Summary of PCA eigenvalues and explained variances
summary(pca_abundance)
library(factoextra)
fviz_screeplot(pca_abundance)
library("dplyr")
#Now, we can use the rownames_to_column function to add the row names of our data as variable:
dataVjGene <- normDtvjg_filtered  # Duplicate example data
dataVjGene <- tibble::rownames_to_column(dataVjGene, "vjGene") # Apply rownames_to_column
dataVjGene <- as.data.frame(normDtvjg_filtered)  # Convert to data frame
dataVjGene <- tibble::rownames_to_column(dataVjGene, "vjGene")  # Apply rownames_to_column
#plot
autoplot(pca_abundance, data = dataVjGene, colour = 'vjGene')
#plot label
autoplot(pca_abundance, data = dataVjGene, colour = 'vjGene', shape = FALSE, label.size = 3)
# Create a PCA plot with coloring by 'groupCol'
autoplot(pca_usage, data = normDt_filtered, colour = 'groupCol', shape = FALSE, label.size = 3)
# Create a PCA plot with coloring by 'vjGene'
ggplot(pca_data, aes(x = PC1, y = PC2, color = vjGene)) +
geom_point() +
labs(title = "PCA Plot with Coloring by 'vjGene'", x = "PC1", y = "PC2") +
theme_minimal()
# Load the datasets
covid <- read.csv("COVID_TCR.csv", header = TRUE, na.strings = "?")
healthyD <- read.csv("HD_TCR.csv", header = TRUE, na.strings = "?")
# Merge the two datasets by 'vjGene'
covid_healthy <- merge(covid, healthyD, by = "vjGene", all = TRUE)
# Set row names and remove 'vjGene' column
row.names(covid_healthy) <- covid_healthy$vjGene
covid_healthy$vjGene <- NULL
# Transpose the merged dataset
dt <- t(covid_healthy)
#make dt numeric (Nas are introduced)
class(dt) <- "numeric"
# Replace NAs with 10^(-7)
dt[is.na(dt)] <- 10^(-7)
# Apply log transformation
logdt <- log(dt)
# Normalize each column
normDt <- scale(logdt)
# Calculate the number of unique values for each column
# This line computes the number of unique values in each column of the 'normDt' data frame.
unique_counts <- apply(normDt, 2, function(x) length(unique(x)))
## Here, we filter the columns in 'normDt' to keep only those with more than 3 unique values.
normDt_filtered <- normDt[, unique_counts > 3]
dim(normDt_filtered)
# Check the number of columns in the original and filtered data frames
num_original_columns <- ncol(normDt)
num_filtered_columns <- ncol(normDt_filtered)
# Print the results
cat("Original number of columns:", num_original_columns, "\n")
cat("Number of columns after filtering:", num_filtered_columns, "\n")
# Calculate the number of columns deleted
num_columns_deleted <- num_original_columns - num_filtered_columns
cat("Number of columns deleted:", num_columns_deleted, "\n")
# Run PCA on the normDt_filtered dataset
pca_usage <- prcomp(normDt_filtered, scale. = TRUE)
# Summary of PCA eigenvalues and explained variances
summary(pca_usage)
# Percentage of explained variances by dimensions
# Load the ggplot2 library
library(ggplot2)
# Create a data frame with PCA scores and 'vjGene' as a column
pca_data <- data.frame(PC1 = pca_usage$x[, 1], PC2 = pca_usage$x[, 2], vjGene = rownames(normDt_filtered))
# Create a PCA plot with coloring by 'vjGene'
ggplot(pca_data, aes(x = PC1, y = PC2, color = vjGene)) +
geom_point() +
labs(title = "PCA Plot with Coloring by 'vjGene'", x = "PC1", y = "PC2") +
theme_minimal()
View(pca_data)
head(pca_data)
tail(pca_data)
# Create a new column 'Cluster' based on the vjGene values
pca_data$Cluster <- ifelse(grepl("^TRB", pca_data$vjGene), "TRB", "HD")
# Plotting
ggplot(pca_data, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
labs(title = "PCA Clustering of Genes in Healthy vs Diseased Patients",
x = "PC1", y = "PC2", color = "Gene Cluster") +
theme_minimal()
install.packages("ggalt")
library(ggalt)
# Assuming your data frame is named pca_data
library(ggplot2)
# Create a new column 'Cluster' based on the vjGene values
pca_data$Cluster <- ifelse(grepl("^TRB", pca_data$vjGene), "TRB", "HD")
# Plotting
ggplot(pca_data, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
geom_encircle(aes(x = PC1, y = PC2, color = Cluster),
data = pca_data %>% filter(Cluster == "TRB"),
size = 1, linetype = "dashed", expand = 0.1) +
geom_encircle(aes(x = PC1, y = PC2, color = Cluster),
data = pca_data %>% filter(Cluster == "HD"),
size = 1, linetype = "dashed", expand = 0.1) +
labs(title = "PCA Clustering of Genes in Healthy vs Diseased Patients",
x = "PC1", y = "PC2", color = "Gene Cluster") +
theme_minimal()
# Create a new column 'Cluster' based on the vjGene values
pca_data$Cluster <- ifelse(grepl("^TRB", pca_data$vjGene), "TRB", "HD")
# Plotting
ggplot(pca_data, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
geom_encircle(aes(x = PC1, y = PC2, color = Cluster),
data = pca_data %>% filter(Cluster == "TRB"),
size = 1, linetype = "dashed", expand = 0.1) +
geom_encircle(aes(x = PC1, y = PC2, color = Cluster),
data = pca_data %>% filter(Cluster == "HD"),
size = 1, linetype = "dashed", expand = 0.1) +
labs(title = "PCA Clustering of Genes in Healthy vs Diseased Patients",
x = "PC1", y = "PC2", color = "Gene Cluster") +
theme_minimal()
library(dplyr)
# Create a new column 'Cluster' based on the vjGene values
pca_data$Cluster <- ifelse(grepl("^TRB", pca_data$vjGene), "TRB", "HD")
# Plotting
ggplot(pca_data, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
geom_encircle(aes(x = PC1, y = PC2, color = Cluster),
data = pca_data %>% filter(Cluster == "TRB"),
size = 1, linetype = "dashed", expand = 0.1) +
geom_encircle(aes(x = PC1, y = PC2, color = Cluster),
data = pca_data %>% filter(Cluster == "HD"),
size = 1, linetype = "dashed", expand = 0.1) +
labs(title = "PCA Clustering of Genes in Healthy vs Diseased Patients",
x = "PC1", y = "PC2", color = "Gene Cluster") +
theme_minimal()
# Plotting
ggplot(pca_data, aes(x = PC1, y = PC2, color = "#4e8dc2")) +
geom_point() +
geom_encircle(aes(x = PC1, y = PC2, color = Cluster),
data = pca_data %>% filter(Cluster == "TRB"),
size = 1, linetype = "dashed", expand = 0.1) +
geom_encircle(aes(x = PC1, y = PC2, color = Cluster),
data = pca_data %>% filter(Cluster == "HD"),
size = 1, linetype = "dashed", expand = 0.1) +
labs(title = "PCA Clustering of Genes in Healthy vs Diseased Patients",
x = "PC1", y = "PC2", color = "Gene Cluster") +
theme_minimal()
# Plotting
ggplot(pca_data, aes(x = PC1, y = PC2, color = Cluster)) +
geom_point() +
geom_encircle(aes(x = PC1, y = PC2, color = Cluster),
data = pca_data %>% filter(Cluster == "TRB"),
size = 1, linetype = "dashed", expand = 0.1) +
geom_encircle(aes(x = PC1, y = PC2, color = Cluster),
data = pca_data %>% filter(Cluster == "HD"),
size = 1, linetype = "dashed", expand = 0.1) +
labs(title = "PCA Clustering of Genes in Healthy vs Diseased Patients",
x = "PC1", y = "PC2", color = "Gene Cluster") +
theme_minimal()
cat("Recall (Sensitivity):", recall, "\n")
# Print the results
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
# Set your working directory to the folder where your file is located
setwd("C:/Users/pauli/OneDrive/√Årea de Trabalho/git_repo/Clustering")
# Read the CSV file
df <- read.csv("bank-additional-full.csv", sep=";")
# View the first few rows of the data
head(df)
View(df)
# Check for missing values in each column
missing_values_by_column <- colSums(is.na(df))
print("Missing values by column:")
print(missing_values_by_column)
# Check for duplicate rows in the entire data frame
total_duplicates <- sum(duplicated(df))
# Display the result
print("Total number of duplicate rows:")
print(total_duplicates)
dim(df)
# Drop duplicate rows from the entire data frame
df <- unique(df)
dim(df)
str(df)
# Specify the columns that should be factors
categorical_columns <- c("job", "marital", "education", "default", "housing",
"loan", "contact", "month", "day_of_week", "poutcome")
# Convert specified columns to factors
df[categorical_columns] <- lapply(df[categorical_columns], as.factor)
# Assuming "df" is your data frame
# Convert "y" to a factor
df$y <- as.factor(df$y)
categorical_vars <- names(df)[sapply(df, is.factor)]
# Create tables for all categorical variables
for (var in categorical_vars) {
cat(paste("Table for", var, ":\n"))
print(table(df[[var]]))
cat("\n")
}
# Selecting only numeric columns
numeric_data <- df[sapply(df, is.numeric)]
# Calculate the correlation matrix
cor_matrix <- cor(numeric_data)
threshold <- .50
# Apply the condition to the correlation matrix
filtered_cor_matrix <- cor_matrix
filtered_cor_matrix[abs(cor_matrix) <= threshold] <- NA
# Print the filtered correlation matrix
print(filtered_cor_matrix)
# Print the correlation matrix
print(cor_matrix)
# Install and load the corrplot package (if not already installed)
# install.packages("corrplot")
library(corrplot)
# Create a heatmap of the correlation matrix
corrplot(cor_matrix, method = "color")
# install.packages("randomForest")
library(randomForest)
# Specify the random forest model
formula <- y ~ .
rf_model <- randomForest(formula, data = df)
# Display variable importance
print(rf_model$importance)
importancee = rf_model$importance
importancee
